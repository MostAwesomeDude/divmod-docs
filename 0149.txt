The comparison in PotatoProgramming could be made more fair by allowing the first example to encapsulate its accumulator (like {{{reduce}}} already does) using MergerDecorator:

{{{
#!python
@merger
def sum(numbers):
    for total, number in numbers:
        yield total + number
}}}

The nice thing about the PotatoProgramming approach is that ''you'' control the 'potato' (iterator/data structure), instead of the other way around.  This makes it much easier and more natural to express problems that involve complex state or work across multiple data structures.

''This is still really slow, and is not the sort of thing that application programmers should concern themselves with.  The term is entirely pejorative.''


In this case, it's slower only because the time spent summing is dwarfed by the outer accumulation loop, which is Python in {{{@merger}}}, but C in {{{reduce}}}.

However, as problems grow larger and more complex, PotatoProgramming solutions generally tend to be ''more'' efficient than 'no potato' code.  Consider the following (finding all usernames in {{{/etc/password}}} having UIDs below 1000):

{{{
#!python
def system_users(lines):
    for line in lines:
        if len(line[:line.find('#')].strip()):
            fields = line.split(':')
            if int(fields[2]) < 1000:
                yield fields[0]
}}}
''{{{timeit.py}}} result:  100000 loops, best of 3: 5.25 usec per loop''

{{{
#!python
def system_users(lines):
    return imap(lambda fields: fields[0],
            ifilter(lambda fields: int(fields[2]) < 1000,
                imap(lambda line: line.split(':'),
                    ifilter(lambda line: len(line[:line.find('#')].strip()),
                        lines))))
}}}
''{{{timeit.py}}} result:  100000 loops, best of 3: 10.9 usec per loop''

Even though the itertools solution is hand-optimized C, the PotatoProgramming solution takes just under half the time, because it preserves the state of the program in one place, instead of fracturing it across many small objects that have to work in isolation.

Not apparent in the above examples is how, for the same reason, PotatoProgramming usually makes it much easier to implement more complex operations, where some parts depend on the state of others.  And ''this'' is exactly what application programmers should be concerning themselves with.

''All you've done above is rewrite the potato program using some constructs sometimes loosely associated with non-potato code.  Using imap() and ifilter() with a PotatoLambda means this is just as much PotatoProgramming as the original version.  Worse, it does things that are *particularly* inefficient in Python, so it's even slower than the naive PotatoProgramming solution.  Consider an implementation of system_users which uses Numeric Python and you may get a better idea of the advantages of non-potato programming.

-exarkun''

----

Here is a more realistic potato/non-potato version:

Potato (cribbed from yours, but reading /etc/passwd instead of a set of lines):

{{{
#!python
def system_users():
    lines = file('/etc/passwd').readlines()
    for line in lines:
        if len(line[:line.find('#')].strip()):
            fields = line.split(':')
            if int(fields[2]) < 1000:
                yield fields[0]
}}}

''{{{timeit.py}}} result: 100000 loops, best of 3: 187 usec per loop''

Non-potato:

{{{
#!python
import pwd
import operator
def system_users():
    users = pwd.getpwall()
    users.sort(key=operator.itemgetter(2))
    for user in users:
        if user[2] < 1000:
            yield user[0]
        else:
            return
}}}

''100000 loops, best of 3: 137 usec per loop''

(I assume your comparisons were not with an actual user database, or you have a CRAZY fast computer...)

Now, you might say, 'That's not fair!  You're using a library for this while I'm implementing it from scratch!'

''As an afterthought, I tested that idea, and wrote this:''

{{{
#!python
import operator

def my_getpwall():
    lines = file('/etc/passwd').readlines()
    for line in lines:
        uncommline = line[:line.find('#')].strip()
        fields = uncommline.split(':')
        yield fields

def system_users():
    users = list(my_getpwall())
    users.sort(key=operator.itemgetter(2))
    for user in users:
        if user[2] < 1000:
            yield user[0]
        else:
            return
}}}
''10000 loops, best of 3: 168 usec per loop -- It's faster even if you ''don't'' write pwd in C...''

However, if 'pwd' did not exist, it would be necessary to invent it.  It might not be any faster than your version if the pwd library were in python, but ''that's the whole point'' -- when you optimize your code, you don't want to do it across boundaries which require the caller to make loops; you want the interface to be expressive so that the loops can be optimized within your interface.  For an ''extreme'' version of PP, implement readline yourself with a {{{for c in string: if c == '\n'...}}}

Ideally, you wouldn't even have to write the 'for user in users' loop yourself.  For example, here's an Axiom snippet to do a similar thing implemented potato-style:

{{{
#!python
def axiom_users(s):
    for u in s.query(User):
        if u.uid < 1000:
            yield u.name
}}}

And here is the non-potato version:

{{{
#!python
def axiom_users(s):
    for u in s.query(User, User.uid < 1000):
        yield u.name
}}}

In other words: force as much work down into the optimizeable guts of the library as possible, then use the interface that way, rather than doing additional iteration and testing yourself.

-glyph
----
